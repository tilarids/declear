{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['record']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pg_toolkit as pgt\n",
    "pgt.toolkit_config.set_pg_conn_string(\"dbname='decl'\")\n",
    "import hashlib\n",
    "import glob\n",
    "import os\n",
    "from IPython.lib import backgroundjobs as bg\n",
    "jobs = bg.BackgroundJobManager()\n",
    "from IPython.display import Image, HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"feed.json\", \"r\") as fp:\n",
    "#     data = json.load(fp)\n",
    "#     for record in data:\n",
    "#         record['path'] = '/Users/tilarids/dev/decl/data/' + hashlib.sha224(record['declaration'].get('url','').encode('utf-8')).hexdigest() + '.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pgt.import_json_into_pg(\"decls\", data, lambda record: record['id'], create_table=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.import_glob_list_into_pg('decls_pdfs', '/Users/tilarids/dev/decl/data/*.pdf')\n",
    "data = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        t.id as id,\n",
    "        t.data->'declaration'->'url' as url,\n",
    "        t.data->'path' as path\n",
    "    FROM decls t\n",
    "    INNER JOIN decls_pdfs dp ON (t.data->>'path'=dp.path)\n",
    "    WHERE t.data->'declaration'->>'url' != ''\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extract_util import extract_borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def extract_fields():\n",
    "    for path in log_progress(data['path']):\n",
    "#         print \"Processing path:\", path,\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for img_path in glob.glob('/Users/tilarids/dev/decl/img_data/' + os.path.basename(path) + \".*.png\")[:2]:\n",
    "            try:\n",
    "                z = None\n",
    "                z = pgt.pg_query_by_id('detected_borders', img_path)\n",
    "            except:\n",
    "                pass\n",
    "            if z:\n",
    "#                 print \"skip\",\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            height, width = img.shape[0], img.shape[1]\n",
    "#             import pdb; pdb.set_trace()\n",
    "            left_border, top_border, right_border, bottom_border = extract_borders(img)\n",
    "            if left_border is None or right_border is None or top_border is None or bottom_border is None:\n",
    "                pgt.import_json_into_pg('detected_borders', \n",
    "                                        [{'path':path, 'img_path':img_path}], \n",
    "                                        lambda record: record['img_path'], \n",
    "                                        create_table=False, \n",
    "                                        skip_duplicates=True)\n",
    "                continue\n",
    "            detected_width = right_border[1] - left_border[1]\n",
    "            detected_height = bottom_border[2] - top_border[2]\n",
    "            out = {'left_border':map(float,left_border),\n",
    "                     'top_border':map(float,top_border),\n",
    "                     'right_border':map(float,right_border),\n",
    "                     'bottom_border':map(float,bottom_border),\n",
    "                     'detected_width':detected_width,\n",
    "                     'detected_height':detected_height,\n",
    "                     'height': height,\n",
    "                     'width': width,\n",
    "                     'img_path':img_path,\n",
    "                     'path':path}\n",
    "#             import pdb; pdb.set_trace()\n",
    "            pgt.import_json_into_pg(\"detected_borders\", [out], lambda record: record['img_path'], create_table=False, skip_duplicates=True)\n",
    "#         print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def apply_tesseract():\n",
    "    for path in log_progress(data['path']):\n",
    "#         print \"Processing path with tesseract:\", path,\n",
    "        for img_path in glob.glob('/Users/tilarids/dev/decl/img_data/' + os.path.basename(path) + \".*.png\")[:2]:\n",
    "            try:\n",
    "                z = None\n",
    "                z = pgt.pg_query_by_id('tesseract_ocr', img_path)\n",
    "            except:\n",
    "                pass\n",
    "            if z:\n",
    "#                 print \"skip\",\n",
    "                continue\n",
    "            try:\n",
    "                out = subprocess.check_output([\"tesseract\", img_path, \"stdout\", \"-l\", \"ukr\"])\n",
    "            except:\n",
    "                continue\n",
    "            record = {'ocr': out,\n",
    "                     'img_path':img_path,\n",
    "                     'path':path}\n",
    "#             import pdb; pdb.set_trace()\n",
    "            pgt.import_json_into_pg(\"tesseract_ocr\", [record], lambda record: record['img_path'], create_table=False, skip_duplicates=True)\n",
    "#         print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n",
      "Starting job # 2 in a separate thread.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BackgroundJob #2: <function apply_tesseract at 0x106930c08>>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.new(extract_fields)\n",
    "jobs.new(apply_tesseract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        t.data->'ocr' as ocr,\n",
    "        t.data->'img_path' as img_path\n",
    "    FROM tesseract_ocr t\n",
    "    WHERE t.data->>'img_path' LIKE '%.0.png' OR t.data->>'img_path' LIKE '%.1.png'\n",
    "\"\"\")\n",
    "z['ocrl'] = z['ocr'].map(lambda x: x.lower())\n",
    "imgs = [s[1]['img_path'] for s in z.iterrows() \n",
    "                     if ((u'клара' in s[1]['ocrl'].lower() or u'кпара' in s[1]['ocrl'])\n",
    "                         and (u'одаток' in s[1]['ocrl']))]\n",
    "                 \n",
    "#                          and (s[1]['img_path'].endswith('.0.png') or s[1]['img_path'].endswith('.1.png')) \n",
    "#                          and (not u'ларант' in s[1]['ocr'] and not u'парант' in s[1]['ocr'])\n",
    "#                         )])\n",
    "imgs = [x[:x[:-4].rfind('.')+1]+str(int(x[x[:-4].rfind('.')+1:-4]) + 1)+\".png\" for x in imgs]\n",
    "pgt.import_list_into_pg('decl_imgs', imgs, col_name='img_path')\n",
    "# imagesList=''.join( [\"<img style='height: 200px; margin: 0px; float: left; border: 1px solid black;' src='%s' />\" % \n",
    "#                      str(s.replace('/Users/tilarids/dev/decl/', '')) for s in imgs]) \n",
    "# display(HTML(imagesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extract_util import four_point_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from extract_util import extract_fields_given_borders\n",
    "\n",
    "z = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        db.data->>'img_path' as img_path,\n",
    "        db.data->'left_border' as left_border,\n",
    "        db.data->'top_border' as top_border,\n",
    "        db.data->'right_border' as right_border,\n",
    "        db.data->'bottom_border' as bottom_border,\n",
    "        db.data->'detected_width' as detected_width,\n",
    "        db.data->'detected_height' as detected_height,\n",
    "        db.data->'height' as height,\n",
    "        db.data->'width' as width\n",
    "    FROM detected_borders db\n",
    "    INNER JOIN decl_imgs di on (di.img_path=db.data->>'img_path')\n",
    "\"\"\")\n",
    "\n",
    "for s in log_progress(z.iterrows(), every=1, size=len(z)):\n",
    "    img_path = s[1]['img_path']\n",
    "    try:\n",
    "        tt = None\n",
    "        tt = pgt.pg_query_by_id('extract_imgs', img_path)\n",
    "    except:\n",
    "        pass\n",
    "    if tt:\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    record = extract_fields_given_borders(img, s[1]['left_border'], s[1]['top_border'], s[1]['right_border'], s[1]['bottom_border'])\n",
    "    if record is None or not record['threshold_met']:\n",
    "        continue\n",
    "    for k,v in record.iteritems():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            if k.endswith('_bin'):\n",
    "                bin_path = s[1]['img_path'].replace('/img_data/', '/extract_img_data/') + \".\" + k.replace('_','.')\n",
    "\n",
    "                np.save(bin_path, v)\n",
    "                record[k] = bin_path + \".npy\"\n",
    "            else:\n",
    "                png_path = s[1]['img_path'].replace('/img_data/', '/extract_img_data/') + \".\" + k + \".png\"\n",
    "                cv2.imwrite(png_path, v)\n",
    "                record[k] = png_path\n",
    "    record['img_path'] = img_path\n",
    "    pgt.import_json_into_pg(\"extract_imgs\", [record], lambda record: record['img_path'], create_table=False, skip_duplicates=True)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracts = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        ei.data->>'second_bin' as second_bin,\n",
    "        ei.data->>'first_bin' as first_bin,\n",
    "        ei.data->'first_width' as first_width,\n",
    "        ei.data->'first_height' as first_height,\n",
    "        ei.data->'second_width' as second_width,\n",
    "        ei.data->'second_height' as second_height,\n",
    "        ei.data->'img_path' as img_path,\n",
    "        d.data->'income'->'5'->>'value' as income,\n",
    "        d.data->'income'->'5'->>'family' as family_income,\n",
    "        d.data->'path' as path\n",
    "    FROM extract_imgs ei\n",
    "    INNER JOIN detected_borders db on (db.data->>'img_path'=ei.data->>'img_path')\n",
    "    INNER JOIN decls d on (db.data->>'path'=d.data->>'path')\n",
    "\"\"\")\n",
    "# len(extracts)\n",
    "extracts[['income','family_income','first_bin','second_bin']].to_json('model_input.json',orient='records')\n",
    "# extracts['second_width'].value_counts()\n",
    "# extracts['first_height'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_extracted_borders(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    left_border, top_border, right_border, bottom_border = extract_borders(img)\n",
    "    cv2.line(img,(left_border[1],left_border[2]),(left_border[3],left_border[4]),(0,0,255),2)\n",
    "    cv2.line(img,(top_border[1],top_border[2]),(top_border[3],top_border[4]),(0,255,0),2)\n",
    "    cv2.line(img,(right_border[1],right_border[2]),(right_border[3],right_border[4]),(255,0,0),2)\n",
    "    cv2.line(img,(bottom_border[1],bottom_border[2]),(bottom_border[3],bottom_border[4]),(255,0,255),2)\n",
    "    print top_border\n",
    "    print img.shape\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.import_json_into_pg(\"full_extract_imgs\", [], lambda record: record['img_path'], create_table=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pgt.pg_query_by_id('decls','vulyk_7_82')['income']['5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "841*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !open /Users/tilarids/dev/decl/data/fc2dfe309d880193fd04672ff6c98ed664e78268e9dd26ba1608cc33.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs.traceback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs.new(extract_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from extract_util import extract_fields_given_borders\n",
    "import copy\n",
    "\n",
    "all_second_pages = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        db.data->>'img_path' as img_path,\n",
    "        db.data->'left_border' as left_border,\n",
    "        db.data->'top_border' as top_border,\n",
    "        db.data->'right_border' as right_border,\n",
    "        db.data->'bottom_border' as bottom_border,\n",
    "        db.data->'detected_width' as detected_width,\n",
    "        db.data->'detected_height' as detected_height,\n",
    "        db.data->'height' as height,\n",
    "        db.data->'width' as width\n",
    "    FROM detected_borders db\n",
    "    where db.data->>'img_path' like '%.1.png'\n",
    "\"\"\")\n",
    "for s in log_progress(all_second_pages.iterrows(), every=1, size=len(all_second_pages)):\n",
    "    img_path = s[1]['img_path']\n",
    "    try:\n",
    "        tt = None\n",
    "        tt = pgt.pg_query_by_id('full_extract_imgs', img_path)\n",
    "    except:\n",
    "        pass\n",
    "    if tt:\n",
    "        continue\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    record = extract_fields_given_borders(img, s[1]['left_border'], s[1]['top_border'], s[1]['right_border'], s[1]['bottom_border'])\n",
    "    if record is None: \n",
    "        continue\n",
    "    out_record = {}\n",
    "    out_record['img_path'] = img_path\n",
    "    \n",
    "    for k,v in record.iteritems():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            out_record['source_key'] = k\n",
    "            if k.endswith('_bin'):\n",
    "                bin_path = img_path.replace('/img_data/', '/full_extract_img_data/') + \".\" + k.replace('_','.')\n",
    "\n",
    "                np.save(bin_path, v)\n",
    "                out_record['bin_path'] = bin_path + \".npy\"\n",
    "            else:\n",
    "                ppm_path = img_path.replace('/img_data/', '/full_extract_img_data/') + \".\" + k + \".ppm\"\n",
    "                cv2.imwrite(ppm_path, v)\n",
    "                out_record['ppm_path'] = ppm_path\n",
    "    pgt.import_json_into_pg(\"full_extract_imgs\", [out_record], lambda record: record['ppm_path'], create_table=False, skip_duplicates=True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.pg_query(\"\"\"\n",
    "    SELECT \n",
    "        fei.data->>'bin_path' as bin_path,\n",
    "        fei.data->>'label' as label\n",
    "    FROM full_extract_imgs fei\n",
    "    WHERE \n",
    "        not fei.data->>'label' is null\n",
    "  \"\"\").to_json('digits_classifier_input.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for x in pgt.pg_query(\"\"\"\n",
    "    SELECT \n",
    "        fei.data->>'ppm_path' as ppm_path\n",
    "    FROM full_extract_imgs fei\n",
    "    WHERE \n",
    "        fei.data->>'label'='space' limit 10\n",
    "  \"\"\")['ppm_path']:\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.imread(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs:\n",
      "0 : <function extract_fields at 0x106930ed8>\n",
      "2 : <function apply_tesseract at 0x106930c08>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "82cbe7d00dfd4572aa1cef2f73725282": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "954fb421f55f45729d9a81488ddbea02": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a36407c27181414aa2e52ef9f2ccb995": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
