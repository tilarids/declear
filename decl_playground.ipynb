{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pg_toolkit as pgt\n",
    "pgt.toolkit_config.set_pg_conn_string(\"dbname='decl'\")\n",
    "import hashlib\n",
    "import glob\n",
    "import os\n",
    "from IPython.lib import backgroundjobs as bg\n",
    "jobs = bg.BackgroundJobManager()\n",
    "from IPython.display import Image, HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"feed.json\", \"r\") as fp:\n",
    "#     data = json.load(fp)\n",
    "#     for record in data:\n",
    "#         record['path'] = '/Users/tilarids/dev/decl/data/' + hashlib.sha224(record['declaration'].get('url','').encode('utf-8')).hexdigest() + '.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pgt.import_json_into_pg(\"decls\", data, lambda record: record['id'], create_table=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.import_glob_list_into_pg('decls_pdfs', '/Users/tilarids/dev/decl/data/*.pdf')\n",
    "data = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        t.id as id,\n",
    "        t.data->'declaration'->'url' as url,\n",
    "        t.data->'path' as path\n",
    "    FROM decls t\n",
    "    INNER JOIN decls_pdfs dp ON (t.data->>'path'=dp.path)\n",
    "    WHERE t.data->'declaration'->>'url' != ''\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def line_intersection(l1, l2):\n",
    "    line1 = ((l1[1], l1[2]), (l1[3],l1[4]))\n",
    "    line2 = ((l2[1], l2[2]), (l2[3],l2[4]))\n",
    "    xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "    ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "    def det(a, b):\n",
    "        return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "    div = det(xdiff, ydiff)\n",
    "    if div == 0:\n",
    "        raise Exception('lines do not intersect')\n",
    "\n",
    "    d = (det(*line1), det(*line2))\n",
    "    x = det(d, xdiff) / div\n",
    "    y = det(d, ydiff) / div\n",
    "    return x, y\n",
    "\n",
    "def extract_borders(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "    if lines is None or len(lines) == 0:\n",
    "        return None, None, None, None\n",
    "    out_lines = []\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "\n",
    "        out_lines.append((theta,x1,y1,x2,y2))\n",
    "\n",
    "    left_border = None\n",
    "    top_border = None\n",
    "    right_border = None\n",
    "    bottom_border = None\n",
    "\n",
    "    for (theta,x1,y1,x2,y2) in out_lines:\n",
    "        if abs(theta - np.pi / 2) < np.pi / 10: # horizontal line.\n",
    "            lint = line_intersection((theta,x1,y1,x2,y2), (0, 0, 0, 0, height))\n",
    "            rint = line_intersection((theta,x1,y1,x2,y2), (0, width, 0, width, height))\n",
    "            if (not top_border or top_border[2] > lint[1]) and lint[1] > 0.02 * height and rint[1] > 0.01 * height:\n",
    "                top_border = (theta,lint[0],lint[1],rint[0],rint[1])\n",
    "            if (not bottom_border or bottom_border[2] < lint[1]) and lint[1] < 0.98 * height and rint[1] < 0.98 * height:\n",
    "                bottom_border = (theta,lint[0],lint[1],rint[0],rint[1])\n",
    "        elif abs(theta) < np.pi / 10: # vertical line\n",
    "            tint = line_intersection((theta,x1,y1,x2,y2), (0, 0, 0, width, 0))\n",
    "            bint = line_intersection((theta,x1,y1,x2,y2), (0, 0, height, width, height))\n",
    "            if (not left_border or left_border[1] > tint[0]) and tint[0] > 0.02 * width and bint[0] > 0.02 * width:\n",
    "                left_border = (theta, tint[0], tint[1], bint[0], bint[1])\n",
    "            if (not right_border or right_border[1] < tint[0]) and tint[0] < 0.98 * width and bint[0] < 0.98 * width:\n",
    "                right_border = (theta,tint[0], tint[1], bint[0], bint[1])\n",
    "\n",
    "    #   cv2.line(img,(left_border[1],left_border[2]),(left_border[3],left_border[4]),(0,0,255),2)\n",
    "    #   cv2.line(img,(top_border[1],top_border[2]),(top_border[3],top_border[4]),(0,255,0),2)\n",
    "    #   cv2.line(img,(right_border[1],right_border[2]),(right_border[3],right_border[4]),(255,0,0),2)\n",
    "    #   cv2.line(img,(bottom_border[1],bottom_border[2]),(bottom_border[3],bottom_border[4]),(255,0,255),2)\n",
    "    return left_border, top_border, right_border, bottom_border\n",
    "# show_extracted_borders('/Users/tilarids/dev/decl/img_data/0278d69820395cf130f098f79b46caa62023627a9a7362295e2c5489.pdf.1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_fields():\n",
    "    for path in log_progress(data['path']):\n",
    "#         print \"Processing path:\", path,\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for img_path in glob.glob('/Users/tilarids/dev/decl/img_data/' + os.path.basename(path) + \".*.png\")[:2]:\n",
    "            try:\n",
    "                z = None\n",
    "                z = pgt.pg_query_by_id('detected_borders', img_path)\n",
    "            except:\n",
    "                pass\n",
    "            if z:\n",
    "#                 print \"skip\",\n",
    "                continue\n",
    "            img = cv2.imread(img_path)\n",
    "            height, width = img.shape[0], img.shape[1]\n",
    "#             import pdb; pdb.set_trace()\n",
    "            left_border, top_border, right_border, bottom_border = extract_borders(img)\n",
    "            if left_border is None or right_border is None or top_border is None or bottom_border is None:\n",
    "                pgt.import_json_into_pg('detected_borders', \n",
    "                                        [{'path':path, 'img_path':img_path}], \n",
    "                                        lambda record: record['img_path'], \n",
    "                                        create_table=False, \n",
    "                                        skip_duplicates=True)\n",
    "                continue\n",
    "            detected_width = right_border[1] - left_border[1]\n",
    "            detected_height = bottom_border[2] - top_border[2]\n",
    "            out = {'left_border':map(float,left_border),\n",
    "                     'top_border':map(float,top_border),\n",
    "                     'right_border':map(float,right_border),\n",
    "                     'bottom_border':map(float,bottom_border),\n",
    "                     'detected_width':detected_width,\n",
    "                     'detected_height':detected_height,\n",
    "                     'height': height,\n",
    "                     'width': width,\n",
    "                     'img_path':img_path,\n",
    "                     'path':path}\n",
    "#             import pdb; pdb.set_trace()\n",
    "            pgt.import_json_into_pg(\"detected_borders\", [out], lambda record: record['img_path'], create_table=False, skip_duplicates=True)\n",
    "#         print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def apply_tesseract():\n",
    "    for path in log_progress(data['path']):\n",
    "#         print \"Processing path with tesseract:\", path,\n",
    "        for img_path in glob.glob('/Users/tilarids/dev/decl/img_data/' + os.path.basename(path) + \".*.png\")[:2]:\n",
    "            try:\n",
    "                z = None\n",
    "                z = pgt.pg_query_by_id('tesseract_ocr', img_path)\n",
    "            except:\n",
    "                pass\n",
    "            if z:\n",
    "#                 print \"skip\",\n",
    "                continue\n",
    "            try:\n",
    "                out = subprocess.check_output([\"tesseract\", img_path, \"stdout\", \"-l\", \"ukr\"])\n",
    "            except:\n",
    "                continue\n",
    "            record = {'ocr': out,\n",
    "                     'img_path':img_path,\n",
    "                     'path':path}\n",
    "#             import pdb; pdb.set_trace()\n",
    "            pgt.import_json_into_pg(\"tesseract_ocr\", [record], lambda record: record['img_path'], create_table=False, skip_duplicates=True)\n",
    "#         print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs.new(extract_fields)\n",
    "jobs.new(apply_tesseract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        t.data->'ocr' as ocr,\n",
    "        t.data->'img_path' as img_path\n",
    "    FROM tesseract_ocr t\n",
    "    WHERE t.data->>'img_path' LIKE '%.0.png' OR t.data->>'img_path' LIKE '%.1.png'\n",
    "\"\"\")\n",
    "z['ocrl'] = z['ocr'].map(lambda x: x.lower())\n",
    "imgs = [s[1]['img_path'] for s in z.iterrows() \n",
    "                     if ((u'клара' in s[1]['ocrl'].lower() or u'кпара' in s[1]['ocrl'])\n",
    "                         and (u'одаток' in s[1]['ocrl']))]\n",
    "                 \n",
    "#                          and (s[1]['img_path'].endswith('.0.png') or s[1]['img_path'].endswith('.1.png')) \n",
    "#                          and (not u'ларант' in s[1]['ocr'] and not u'парант' in s[1]['ocr'])\n",
    "#                         )])\n",
    "imgs = [x[:x[:-4].rfind('.')+1]+str(int(x[x[:-4].rfind('.')+1:-4]) + 1)+\".png\" for x in imgs]\n",
    "pgt.import_list_into_pg('decl_imgs', imgs, col_name='img_path')\n",
    "# imagesList=''.join( [\"<img style='height: 200px; margin: 0px; float: left; border: 1px solid black;' src='%s' />\" % \n",
    "#                      str(s.replace('/Users/tilarids/dev/decl/', '')) for s in imgs]) \n",
    "# display(HTML(imagesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = pts\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        db.data->>'img_path' as img_path,\n",
    "        db.data->'left_border' as left_border,\n",
    "        db.data->'top_border' as top_border,\n",
    "        db.data->'right_border' as right_border,\n",
    "        db.data->'bottom_border' as bottom_border,\n",
    "        db.data->'detected_width' as detected_width,\n",
    "        db.data->'detected_height' as detected_height,\n",
    "        db.data->'height' as height,\n",
    "        db.data->'width' as width\n",
    "    FROM detected_borders db\n",
    "    INNER JOIN decl_imgs di on (di.img_path=db.data->>'img_path')\n",
    "\"\"\")\n",
    "\n",
    "for s in log_progress(z.iterrows(), every=1, size=len(z)):\n",
    "    img_path = s[1]['img_path']\n",
    "    try:\n",
    "        z = None\n",
    "        z = pgt.pg_query_by_id('extract_imgs', img_path)\n",
    "    except:\n",
    "        pass\n",
    "    if z:\n",
    "        continue\n",
    "\n",
    "    if not s[1]['left_border']:\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = s[1]['height'], s[1]['width']\n",
    "    detected_height = s[1]['detected_height']\n",
    "    detected_width = s[1]['detected_width']\n",
    "#     import pdb; pdb.set_trace()\n",
    "    left_border = map(int, list(s[1]['left_border']))\n",
    "    right_border = map(int, list(s[1]['right_border']))\n",
    "    top_border = map(int, list(s[1]['top_border']))\n",
    "    bottom_border = map(int, list(s[1]['bottom_border']))\n",
    "    \n",
    "    WIDTH_THRESHOLD_MIN, WIDTH_THRESHOLD_MAX = (0.75, 0.86)\n",
    "    HEIGHT_THRESHOLD_MIN, HEIGHT_THRESHOLD_MAX = (0.8, 0.97)\n",
    "    if (HEIGHT_THRESHOLD_MIN < float(detected_height) / height < HEIGHT_THRESHOLD_MAX and\n",
    "        WIDTH_THRESHOLD_MIN < float(detected_width) / width < WIDTH_THRESHOLD_MAX):\n",
    "        \n",
    "        tl = line_intersection(left_border, top_border)\n",
    "        tr = line_intersection(right_border, top_border)\n",
    "        bl = line_intersection(left_border, bottom_border)\n",
    "        br = line_intersection(right_border, bottom_border)\n",
    "        warp = four_point_transform(img, np.array([tl, tr, br, bl]))\n",
    "        wh, ww = warp.shape[0], warp.shape[1]\n",
    "        \n",
    "        TL1 = (0.615866388308977 * ww, 0.13972602739726028 * wh)\n",
    "        TR1 = (0.7891440501043842 * ww, 0.13972602739726028 * wh)\n",
    "        BL1 = (0.615866388308977 * ww, 0.16712328767123288 * wh)\n",
    "        BR1 = (0.7891440501043842 * ww, 0.16712328767123288 * wh)\n",
    "\n",
    "        TL2 = (0.7933194154488518 * ww, 0.13972602739726028 * wh)\n",
    "        TR2 = (0.9665970772442589 * ww, 0.13972602739726028 * wh)\n",
    "        BL2 = (0.7933194154488518 * ww, 0.16712328767123288 * wh)\n",
    "        BR2 = (0.9665970772442589 * ww, 0.16712328767123288 * wh)\n",
    "\n",
    "        record = {'img_path': img_path}\n",
    "        for k,v in {'first': np.array([TL1, TR1, BR1, BL1]), \n",
    "                    'second': np.array([TL2, TR2, BR2, BL2])\n",
    "                   }.iteritems():\n",
    "            im = four_point_transform(warp, v)\n",
    "            imh,imw = im.shape[0], im.shape[1]\n",
    "            new_path = s[1]['img_path'].replace('/img_data/', '/extract_img_data/') + \".\" + k + \".png\"\n",
    "            cv2.imwrite(new_path, im)\n",
    "            record[k] = new_path\n",
    "            record[k+'_width'] = imw\n",
    "            record[k+'_height'] = imh\n",
    "            \n",
    "            imbin = cv2.adaptiveThreshold(cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2GRAY), (95, 22)) ,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "            bin_path = s[1]['img_path'].replace('/img_data/', '/extract_img_data/') + \".\" + k + \".bin\"\n",
    "            \n",
    "            np.save(bin_path, imbin)\n",
    "            record[k+'_bin'] = bin_path + \".npy\"\n",
    "            \n",
    "        pgt.import_json_into_pg(\"extract_imgs\", [record], lambda record: record['img_path'], create_table=False, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracts = pgt.pg_query(\"\"\"\n",
    "    SELECT\n",
    "        ei.data->>'second_bin' as second_bin,\n",
    "        ei.data->>'first_bin' as first_bin,\n",
    "        ei.data->'first_width' as first_width,\n",
    "        ei.data->'first_height' as first_height,\n",
    "        ei.data->'second_width' as second_width,\n",
    "        ei.data->'second_height' as second_height,\n",
    "        ei.data->'img_path' as img_path,\n",
    "        d.data->'income'->'5'->>'value' as income,\n",
    "        d.data->'income'->'5'->>'family' as family_income,\n",
    "        d.data->'path' as path\n",
    "    FROM extract_imgs ei\n",
    "    INNER JOIN detected_borders db on (db.data->>'img_path'=ei.data->>'img_path')\n",
    "    INNER JOIN decls d on (db.data->>'path'=d.data->>'path')\n",
    "\"\"\")\n",
    "# len(extracts)\n",
    "extracts[['income','family_income','first_bin','second_bin']].to_json('model_input.json',orient='records')\n",
    "# extracts['second_width'].value_counts()\n",
    "# extracts['first_height'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_extracted_borders(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    left_border, top_border, right_border, bottom_border = extract_borders(img)\n",
    "    cv2.line(img,(left_border[1],left_border[2]),(left_border[3],left_border[4]),(0,0,255),2)\n",
    "    cv2.line(img,(top_border[1],top_border[2]),(top_border[3],top_border[4]),(0,255,0),2)\n",
    "    cv2.line(img,(right_border[1],right_border[2]),(right_border[3],right_border[4]),(255,0,0),2)\n",
    "    cv2.line(img,(bottom_border[1],bottom_border[2]),(bottom_border[3],bottom_border[4]),(255,0,255),2)\n",
    "    print top_border\n",
    "    print img.shape\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.import_json_into_pg(\"detected_borders\", [], lambda record: record['img_path'], create_table=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgt.pg_query_by_id('decls','vulyk_7_82')['income']['5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "841*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open /Users/tilarids/dev/decl/data/fc2dfe309d880193fd04672ff6c98ed664e78268e9dd26ba1608cc33.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "0257870a3ef747bcb470bd36851c3c57": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "31f1f91f6ee74244b5376b73e8d40159": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "35f41b9a15e549c5b948460adeeebda0": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "4bcfcde54a124ee796ea455e6af545d8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "71f7c58aa9664203b11b4b779bc2f515": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a788a05d8cf646ecbf3f5a4abf1d9b69": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b8acc0ea812043d6ae6b5001380b2b4f": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "ce34bc438b0c42ab91e69a850a65c4da": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f3409310f063410e96c7ed5437dd9095": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
